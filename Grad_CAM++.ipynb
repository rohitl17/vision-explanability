{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Flatten, Dense, GlobalAveragePooling2D,Dropout,Conv2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Note this code assumes you have two class model and the last layer of the model is softmax.\n",
    "Heatmaps are created in the default resolution of (768,768).\n",
    "The default size of model input is (224,224)\n",
    "\n",
    "'''\n",
    "\n",
    "global graph\n",
    "graph = tf.get_default_graph()\n",
    "def get_score_and_interm_output(cv2_input_image, DenseNetImageNet121_model):\n",
    "\n",
    "     with graph.as_default():\n",
    "\n",
    "        #define your tensor placeholders for, labels and images\n",
    "        label_vector1 = tf.placeholder(\"float\", [None, 2])\n",
    "\n",
    "        cost = DenseNetImageNet121_model.output.op.inputs[0]*label_vector1\n",
    "\n",
    "        # Get last convolutional layer gradients for generating gradCAM++ visualization\n",
    "        target_conv_layer = DenseNetImageNet121_model.layers[-5].output\n",
    "        target_conv_layer_grad = K.gradients(cost, target_conv_layer)[0]\n",
    "        \n",
    "        #Predicted probabilities\n",
    "        pred = DenseNetImageNet121_model.layers[-1].output\n",
    "        \n",
    "\n",
    "        first_grad = []\n",
    "        start1 = time() \n",
    "        for i in range(2):\n",
    "            output = [0.0]*DenseNetImageNet121_model.layers[-1].output.get_shape().as_list()[1] #one-hot embedding for desired class activations\n",
    "            #creating the output vector for the respective class\n",
    "            output[i] = 1.0\n",
    "            output = np.array(output)\n",
    "            \n",
    "            gradient_function = K.function([DenseNetImageNet121_model.layers[0].input,label_vector1], [target_conv_layer, target_conv_layer_grad, pred])\n",
    "\n",
    "            [conv_output1, conv_first_grad, prediction] = gradient_function([cv2_input_image[None,:,:,:],output.reshape((1,-1))])\n",
    "        \n",
    "            first_grad.append(conv_first_grad[0])\n",
    "            prediction = prediction[0,:]\n",
    "        \n",
    "        end1 = time()\n",
    "        print('Time to calculate gradients is {0}'.format(end1-start1))\n",
    "        return conv_output1, first_grad, prediction\n",
    "\n",
    "\n",
    "\n",
    "def weights_all(score_grad,conv_output,prediction):\n",
    "    \n",
    "    temp1 = 0\n",
    "    for j in range(2):\n",
    "        temp1 += prediction[j]*score_grad[j]\n",
    "        \n",
    "        \n",
    "    conv_first_grad = []\n",
    "    for i in range(2):            \n",
    "        conv_first_grad.append(prediction[i]*(score_grad[i] - temp1))\n",
    "        \n",
    "    temp2 = 0\n",
    "    for j in range(2):\n",
    "        temp2 += conv_first_grad[j]*score_grad[j]\n",
    "        \n",
    "    conv_second_grad = []\n",
    "    for i in range(2):\n",
    "        conv_second_grad.append(conv_first_grad[i]*(score_grad[i] - temp1) - prediction[i]*temp2)\n",
    "        \n",
    "    temp3 = 0\n",
    "    for j in range(2):\n",
    "        temp3 += conv_second_grad[j]*score_grad[j]\n",
    "        \n",
    "    conv_third_grad = []\n",
    "    for i in range(2):\n",
    "        conv_third_grad.append(conv_second_grad[i]*(score_grad[i] - temp1) - \\\n",
    "                                2*conv_first_grad[i]*temp2 - prediction[i]*temp3)\n",
    "        \n",
    "        \n",
    "        \n",
    "    weights_temp = []\n",
    "    cams = []\n",
    "    for i in range(2):\n",
    "        global_sum = np.sum(conv_output[0].reshape((-1,conv_first_grad[i].shape[2])), axis=0)\n",
    "\n",
    "        alpha_num = conv_second_grad[i]\n",
    "        alpha_denom = conv_second_grad[i]*2.0 + conv_third_grad[i]*global_sum.reshape((1,1,conv_first_grad[i].shape[2]))\n",
    "        alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
    "        alphas = alpha_num/alpha_denom\n",
    "\n",
    "        weights = np.maximum(conv_first_grad[i], 0.0)\n",
    "        #normalizing the alphas\n",
    "        \"\"\"\t\n",
    "        alpha_normalization_constant = np.sum(np.sum(alphas, axis=0),axis=0)\n",
    "\n",
    "        alphas /= alpha_normalization_constant.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "        \"\"\"\n",
    "\n",
    "        alphas_thresholding = np.where(weights, alphas, 0.0)\n",
    "\n",
    "        alpha_normalization_constant = np.sum(np.sum(alphas_thresholding, axis=0),axis=0)\n",
    "        alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
    "\n",
    "\n",
    "        alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad[i].shape[2]))\n",
    "\n",
    "\n",
    "\n",
    "        deep_linearization_weights = np.sum((weights*alphas).reshape((-1,conv_first_grad[i].shape[2])),axis=0)\n",
    "        \n",
    "        weights_temp.append(deep_linearization_weights)\n",
    "        \n",
    "        \n",
    "        grad_CAM_map = np.sum(deep_linearization_weights*conv_output[0], axis=2)\n",
    "\n",
    "        # Passing through ReLU\n",
    "        cam = np.maximum(grad_CAM_map, 0)\n",
    "        cam = cam / np.max(cam) # scale 0 to 1.0   \n",
    "\n",
    "        cam = cv2.resize(cam, (224,224))\n",
    "        # Passing through ReLU\n",
    "        cam = np.maximum(grad_CAM_map, 0)\n",
    "        cam = cam / np.max(cam) # scale 0 to 1.0    \n",
    "        cam = cv2.resize(cam, (224,224))\n",
    "\n",
    "        cams.append(cam)\n",
    "        \n",
    "    return np.array(cams)\n",
    "\n",
    "def get_cam_picture(cams,dis_idx):\n",
    "    #Create the class activation map.\n",
    "    all_cams = []\n",
    "    for m in dis_idx:\n",
    "        grad_CAM_map = cv2.resize((cams[m]*-1.0) + 1.0, (768, 768), cv2.INTER_LINEAR)\n",
    "        jetcam = cv2.applyColorMap(np.uint8(255 * grad_CAM_map), cv2.COLORMAP_JET)\n",
    "        all_cams.append(jetcam)\n",
    "    \n",
    "    return all_cams\n",
    "\n",
    "\n",
    "\n",
    "def save_fig(im_data,mp,path):\n",
    "    dpi = 80\n",
    "\n",
    "    height, width, nbands = im_data.shape\n",
    "\n",
    "\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, interpolation='nearest')\n",
    "    ax.imshow(mp/255.,alpha=0.3)#,cmap='jet')\n",
    "#     ax.imshow(mp)\n",
    "\n",
    "    ax.set(xlim=[0, width], ylim=[height, 0], aspect=1)\n",
    "\n",
    "    fig.savefig(path, dpi=dpi, transparent=True)\n",
    "    plt.close()\n",
    "    \n",
    "def cam_predict(img1,img,fname,shape,dest,class_names,model,threshold):\n",
    "    \n",
    "    img = img\n",
    "    conv_outputs,class_score_grads,preds = get_score_and_interm_output(img1,model)\n",
    "    dis_probs = {}\n",
    "    dis_idx = []\n",
    "\n",
    "    if(preds[1]>threshold):\n",
    "        dis_idx.append(1)\n",
    "        dis_probs[class_names[1]] = preds[1]\n",
    "        pathology = class_names[1]\n",
    "\n",
    "\n",
    "    dis_idx = np.array(dis_idx)\n",
    "    cams = weights_all(class_score_grads,conv_outputs,preds)\n",
    "    all_cams = get_cam_picture(cams,dis_idx)\n",
    "    \n",
    "    res = img\n",
    "\n",
    "    #Changing the size of the image so that the heat map can be fitted on the dicom.\n",
    "    #img = cv2.resize(img,(shape[1],shape[0]))\n",
    "    img = cv2.resize(img,(768,768))\n",
    "    for i in range(0,len(dis_probs)):    \n",
    "        dis_name = class_names[dis_idx][i]\n",
    "        path = dest + \"{0}_{1}_heatmap_grad_cam_plus_plus.png\".format(fname,dis_name)\n",
    "        save_fig(img,cv2.resize(all_cams[i],(768,768)),path)\n",
    "\n",
    "    return preds,res,all_cams\n",
    "\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def img_standardization(x):\n",
    "    \n",
    "#     x=cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x=x.astype('float16')/255.\n",
    "#     return x\n",
    "    return ((x-imagenet_mean)/imagenet_std)\n",
    "\n",
    "\n",
    "def get_heatmaps(path,dest,class_names,model,threshold):\n",
    "    start2 = time()\n",
    "    img_name = path.split('/')[-1].strip('.png')\n",
    "    x = cv2.imread(path)\n",
    "    x = cv2.resize(x,(224,224))\n",
    "    x1 = img_standardization(x)\n",
    "    shape = x.shape\n",
    "    preds,_,_ = cam_predict(x1,x,img_name,shape,dest,class_names,model,threshold)\n",
    "    if preds[1] > threshold:\n",
    "        print(\"Heatmaps Created\",img_name)\n",
    "    else:\n",
    "        print(\"Heatmaps not created\",img_name)\n",
    "    print(preds)\n",
    "    end2 = time()\n",
    "    print('Time for entire process is {0}'.format(end2 - start2))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defining model\n",
    "dense_model = DenseNet121(weights='imagenet', include_top=False,input_shape=(224,224,3),pooling='avg')\n",
    "\n",
    "preds = Dense(2,activation='softmax')(dense_model.output)\n",
    "model = Model(dense_model.input,preds)\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.load_weights('./Weights/Edema_vs_Healthy_pretrained_CHAI_TBvsNTB.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "all_pngs=glob.glob('./Edema_Images_ToBeAnnotated/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Please define class names as per your model\n",
    "cls = ['Healthy',\n",
    "'Edema']\n",
    "cls = np.array(cls)\n",
    "\n",
    "for idx, i in enumerate(all_pngs):\n",
    "    if idx%100==0:\n",
    "        get_heatmaps(i,'./Heatmaps_0.11/',cls,model,threshold = 0.11)\n",
    "        print (idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pngs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_categorical([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
